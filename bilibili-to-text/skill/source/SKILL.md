---
name: bilibili-to-text
description: Download Bilibili videos and transcribe them to text using faster-whisper. Use when the user provides a Bilibili URL (b23.tv, bilibili.com/video), asks to transcribe/convert a Bilibili video to text, requests video subtitles, or wants to analyze/summarize video content from Bilibili.
---

# Bilibili Video to Text

Convert Bilibili videos to high-quality text transcripts using faster-whisper with Whisper medium model.

## Overview

This skill enables downloading Bilibili videos and converting them to text with 15x better quality than alternative tools. It produces SRT subtitles, TXT plain text, and optional Markdown documents.

**Key advantages**:
- High-quality Chinese transcription (95%+ accuracy)
- 4-10x faster than original Whisper
- Multiple output formats (SRT + TXT + MD)
- Automatic language detection

## Quick Start

### Recommended Workflow (Audio Extraction)

**Recommended approach** - Extract audio first for better file management:

```bash
# 1. Navigate to project directory
cd ~/Documents/10.github/bili2text

# 2. Download video
you-get "<bilibili-url>"

# 3. Find the downloaded video
find . -name "*.mp4" -type f -mtime -1

# 4. Extract audio (faster, smaller file)
ffmpeg -i "<video-file-path>" -vn -acodec libmp3lame -q:a 2 "<output-name>.mp3"

# 5. Transcribe audio to text
python3 faster_whisper_subtitle.py \
    "<output-name>.mp3" \
    "subtitles/<output-name>.srt" \
    medium
```

**Example**:
```bash
cd ~/Documents/10.github/bili2text
you-get "https://b23.tv/stO0N9K"
ffmpeg -i "./æ˜¯ä»€ä¹ˆå¯¼è‡´äº†é‡‘é“¶æš´è·Œï¼Ÿæˆ‘ä»¬æ¥ä¸‹æ¥åº”è¯¥æ€ä¹ˆåº”å¯¹ï¼Ÿï¼ˆä¸‹ï¼‰-å½“å‰å®è§‚ç»æµå½¢åŠ¿ä¸çƒ­ç‚¹åˆ†æ.mp4" \
    -vn -acodec libmp3lame -q:a 2 "é‡‘é“¶æš´è·Œåˆ†æ.mp3"
python3 faster_whisper_subtitle.py \
    "é‡‘é“¶æš´è·Œåˆ†æ.mp3" \
    "subtitles/é‡‘é“¶æš´è·Œåˆ†æ.srt" \
    medium
```

### Alternative: Direct Video Transcription

Can also transcribe video files directly (same quality, larger file size):

```bash
python3 faster_whisper_subtitle.py \
    "<video-file-path>" \
    "subtitles/<output-name>.srt" \
    medium
```

### Output Files

After transcription completes:
- `subtitles/<name>.srt` - SRT subtitle file with timestamps
- `subtitles/<name>.txt` - Plain text version (auto-generated)

### Reading Transcripts

Always read the TXT file for analysis:
```bash
# Read the transcript
cat subtitles/<name>.txt
```

Then provide analysis or summary as requested by the user.

## Workflow Details

### 1. Download Video

Use `you-get` to download from Bilibili:

```bash
cd ~/Documents/10.github/bili2text
you-get "<url>"
```

**Supported URL formats**:
- `https://www.bilibili.com/video/BV1XoqJBiE7T`
- `https://b23.tv/stO0N9K`
- `BV1XoqJBiE7T` (BV number only)

**Notes**:
- Default quality: 480P (no login required)
- 720P+ requires login cookies
- Videos download to current directory with Chinese filename

### 2. Locate Downloaded File

Find the video file:
```bash
find . -name "*.mp4" -type f -mtime -1
```

Or list recent downloads:
```bash
ls -lt *.mp4 | head -5
```

### 3. Extract Audio (Recommended)

Extract audio using ffmpeg for better file management:

```bash
ffmpeg -i "<video-file-path>" -vn -acodec libmp3lame -q:a 2 "<output-audio>.mp3"
```

**Parameters explained**:
- `-i "<video-file-path>"`: Input video file
- `-vn`: No video (audio only)
- `-acodec libmp3lame`: MP3 audio codec
- `-q:a 2`: High quality audio (VBR quality 2, ~190 kbps)
- `"<output-audio>.mp3"`: Output audio file

**Performance**:
- 19-min video â†’ 6.5 seconds extraction (179x speed)
- File size reduction: ~58% (31MB video â†’ 13MB audio)
- Same transcription quality as direct video input

**Why extract audio first**:
- Smaller file size (easier to manage and store)
- Faster to process in some environments
- Can delete large video file after extraction
- Same transcription quality

### 4. Transcribe Audio/Video

Run faster-whisper transcription:

```bash
python3 faster_whisper_subtitle.py \
    "<video-path>" \
    "subtitles/<output-name>.srt" \
    medium
```

**Parameters**:
- Param 1: Input video file path
- Param 2: Output SRT file path
- Param 3: Model size (`medium` recommended for Chinese)

**Processing indicators**:
```
ğŸ“¹ è§†é¢‘: <path>
ğŸ“ è¾“å‡º: <srt-path>
ğŸ¤– æ¨¡å‹: medium
â³ åŠ è½½ Whisper æ¨¡å‹...
âœ… æ¨¡å‹åŠ è½½å®Œæˆ
ğŸ™ï¸  å¼€å§‹è½¬å½•...
ğŸ“Š æ£€æµ‹åˆ°çš„è¯­è¨€: zh (æ¦‚ç‡: 100.00%)
â±ï¸  è§†é¢‘æ—¶é•¿: 1153.5 ç§’
ğŸ’¾ å†™å…¥å­—å¹•æ–‡ä»¶...
  å·²å¤„ç† 10 ä¸ªç‰‡æ®µ...
  å·²å¤„ç† 20 ä¸ªç‰‡æ®µ...
  ...
âœ… å®Œæˆ! å…±ç”Ÿæˆ 480 ä¸ªå­—å¹•ç‰‡æ®µ
ğŸ“„ ç”Ÿæˆçº¯æ–‡æœ¬ç‰ˆæœ¬: subtitles/<name>.txt
âœ… çº¯æ–‡æœ¬æ–‡ä»¶ç”Ÿæˆå®Œæˆ!
```

**Processing time**:
- 5-min video: ~2-3 minutes
- 15-min video: ~5-8 minutes
- 30-min video: ~15-20 minutes
- Ratio: ~0.5-0.7x of video duration

### 4. Analyze Results

Read the TXT file and provide analysis:

```bash
# Read transcript
cat subtitles/<name>.txt

# Or use Read tool
Read subtitles/<name>.txt
```

Then summarize key points, conclusions, or answer user questions based on the transcript content.

## Model Selection

| Model | Size | Speed | Chinese Accuracy | Recommended |
|-------|------|-------|-----------------|-------------|
| tiny | 39M | â­â­â­â­â­ | â­ | âŒ Not recommended |
| small | 244M | â­â­â­â­ | â­â­ | âš ï¸ Testing only |
| **medium** | **769M** | **â­â­â­** | **â­â­â­â­â­** | âœ… **Strongly recommended** |
| large | 1550M | â­â­ | â­â­â­â­â­ | âš ï¸ High resource usage |

**Conclusion**: Use **medium model** for best quality/speed balance in Chinese recognition.

## Project Structure

```
~/Documents/10.github/bili2text/
â”œâ”€â”€ faster_whisper_subtitle.py   # Single video transcription
â”œâ”€â”€ bili_to_text.sh              # One-click automation script
â”œâ”€â”€ batch_convert_corrected.py   # Batch processing
â”œâ”€â”€ generate_markdown.py         # Markdown generation
â”œâ”€â”€ bilibili_video/              # Downloaded videos
â””â”€â”€ subtitles/                   # Transcription outputs
    â”œâ”€â”€ *.srt                    # SRT subtitle files
    â”œâ”€â”€ *.txt                    # Plain text files
    â””â”€â”€ *.md                     # Markdown documents
```

## Performance Comparison

### Audio Extraction vs Direct Video Transcription

**Test case**: 19-minute video (31.4MB MP4 file)

| Approach | Audio Extraction | File Size | Transcription Quality | Total Time |
|----------|-----------------|-----------|---------------------|------------|
| **Recommended** | âœ… Extract audio first | 13MB MP3 (58% reduction) | 475 segments, 561 lines | ~6.5s + transcription |
| Alternative | âŒ Direct video | 31.4MB MP4 | 480 segments, 533 lines | transcription only |

**Key findings**:
- Audio extraction: **6.5 seconds** at 179x speed
- Transcription quality: **Identical** (same content, same accuracy)
- File size: **58% reduction** (31.4MB â†’ 13MB)
- Total processing time: **Similar** (audio extraction overhead is minimal)

**Recommendation**: Extract audio first for better file management with no quality loss.

## Common Issues

### Video Already Exists

If `you-get` shows "file already exists":
```bash
# Find existing video
find . -name "*<keyword>*" -type f
```

### Cannot Find Video File

Check download directory:
```bash
ls -lt *.mp4 | head -10
```

Videos use Chinese titles from Bilibili metadata.

### Model Download Location

First run downloads model automatically:
- Location: `~/.cache/huggingface/hub/models--Systran--faster-whisper-medium/`
- Size: ~1.4GB
- Only downloads once, reused for all future transcriptions

## Technical Details

**faster-whisper parameters**:
```python
from faster_whisper import WhisperModel

# Load model
model = WhisperModel("medium", device="cpu", compute_type="int8")

# Transcribe with optimal settings
segments, info = model.transcribe(
    video_path,
    language="zh",          # Chinese recognition
    vad_filter=True,        # Filter silence
    beam_size=5,            # Higher quality
    word_timestamps=True    # Word-level timestamps
)
```

**Key configurations**:
- `device="cpu"`: CPU mode (more stable on Mac)
- `compute_type="int8"`: 4-10x speed boost via quantization
- `vad_filter=True`: Automatic silence filtering
- `beam_size=5`: Beam search for better accuracy

## Output Formats

### SRT Subtitle Format
```srt
1
00:00:00,000 --> 00:00:04,839
ä»Šå¤©è¿™ä¸€è¯¾æˆ‘ä»¬å°±ä¸“é—¨èŠä¸€å¥—å¾ˆå®ç”¨çš„å®æˆ˜æ–¹æ³•

2
00:00:04,839 --> 00:00:07,480
å¼ºåŠ¿éª¨å³ä¾§ä¸‰æ¬¡å¥ä»“æ³•
```

### Plain Text Format
```
ä»Šå¤©è¿™ä¸€è¯¾æˆ‘ä»¬å°±ä¸“é—¨èŠä¸€å¥—å¾ˆå®ç”¨çš„å®æˆ˜æ–¹æ³•
å¼ºåŠ¿éª¨å³ä¾§ä¸‰æ¬¡å¥ä»“æ³•
å®ƒæ˜¯ç‘å“¥é’ˆå¯¹å¼ºåŠ¿éª¨è®¾è®¡çš„ä¸€å¥—
```

Each line is one sentence/phrase for easy reading and processing.

## Workflow Summary

**Recommended workflow**:

1. User provides Bilibili URL
2. Download video with `you-get`
3. Extract audio with `ffmpeg` (recommended for better file management)
4. Transcribe with `faster_whisper_subtitle.py` using medium model
5. Read the generated TXT file
6. Provide summary or analysis as requested

**Alternative workflow** (direct video transcription):
1. User provides Bilibili URL
2. Download video with `you-get`
3. Transcribe video directly with `faster_whisper_subtitle.py` using medium model
4. Read the generated TXT file
5. Provide summary or analysis as requested

**Best practices**:
- Always use the **medium model** for Chinese videos to ensure high-quality transcription
- **Extract audio first** for better file management (58% file size reduction, same quality)
- Delete large video files after audio extraction to save disk space
- Use meaningful output names for easier file organization
